<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>blog of meurice</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://meurice.xyz/"/>
  <updated>2020-07-21T02:08:24.860Z</updated>
  <id>http://meurice.xyz/</id>
  
  <author>
    <name>meurice</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>特征工程（待更新）</title>
    <link href="http://meurice.xyz/2020/ckcvmon6l0004p4lxfe4h6mzj/"/>
    <id>http://meurice.xyz/2020/ckcvmon6l0004p4lxfe4h6mzj/</id>
    <published>2020-07-18T03:42:42.000Z</published>
    <updated>2020-07-21T02:08:24.860Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言　　"></a>前言　　</h2><p>　　数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。</p><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>　　特征工程是对原始数据进行一系列工程处理，将其提炼为特征，作为输入供算法和模型使用，简单来说，就是通过X，创造新的X’，目的是去除原始数据中的杂质和冗余，设计更高效的特征以刻画求解的问题与预测模型之间的关系，其本质是一个表示和展现数据的过程。基本的操作包括，衍生（升维），筛选（降维）等。<br>　　例如某分类器接收身高、体重两个参数来判断这个人是否肥胖，仅通过体重无法判断某个人的胖瘦，对于该例，一个非常经典的特征工程是，BMI指数，BMI=体重/(身高^2)，通过BMI指数，可以清晰地对一个人的胖瘦进行刻画。  </p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>　　常见的数据可分为结构化数据（例如关系型数据库的表）和非结构化数据（文本、图像、音频、视频等）。</p><h3 id="单特征"><a href="#单特征" class="headerlink" title="单特征"></a>单特征</h3><h4 id="标准化与归一化"><a href="#标准化与归一化" class="headerlink" title="标准化与归一化"></a>标准化与归一化</h4><p>　　该部分可以参考<a href="http://meurice.xyz/2020/ckcqevh3t0004xclxakyx24ma/">数据预处理——归一化与标准化</a>。</p><h4 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h4><h5 id="均值-中位数-众数-固定值填充"><a href="#均值-中位数-众数-固定值填充" class="headerlink" title="均值/中位数/众数/固定值填充"></a>均值/中位数/众数/固定值填充</h5><p>　　如果样本属性的距离是可度量的，则使用该属性有效值的平均值来补全；如果样本属性的距离不可度量，则可以采用众数或者中位数来补全。<br>　　或可根据某一特征对样本进行分类/聚合后（例如船运GPS数据，根据运单号进行聚合后，对样本数据缺失值进行填充），根据同类其他样本该属性的均值补全缺失值，同上述方法类似。<br>　　对于缺失值也可以采用固定的数值来进行填充。</p><h5 id="建模预测"><a href="#建模预测" class="headerlink" title="建模预测"></a>建模预测</h5><p>　　将缺失值字段作为预测对象，建立模型对其进行预测，根据该模型补全原训练集的缺失值。这个方法根本的缺陷是如果其他属性和缺失属性无关，则预测的结果毫无意义；但若模型对预测字段拟合效果相当好，则说明这个缺失属性没必要纳入数据集；一般的情况是介于两者之间。</p><h5 id="高维映射"><a href="#高维映射" class="headerlink" title="高维映射"></a>高维映射</h5><p>　　将属性映射到高维空间，采用独热码编码（one-hot）技术。将包含 K 个离散取值范围的属性值扩展为 K+1 个属性值，若该属性值缺失，则扩展后的第 K+1 个属性值置为 1。<br>　　这种做法既保留了所有的信息，也未添加任何额外信息，但会增加数据的维度，增大了计算量，一般在样本量非常大时效果才比较好。</p><h5 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h5><p>　　如多重插补、压缩感知和矩阵补全等，此处不具体展开，可以参考<a href="https://mp.weixin.qq.com/s/BnTXjzHSb5-4s0O0WuZYlg" target="_blank" rel="noopener">这篇文章</a>。</p><h4 id="特征二值化"><a href="#特征二值化" class="headerlink" title="特征二值化"></a>特征二值化</h4><p>　　 设立阈值，将特征二值化。<br>　　<img src= "/img/loading.gif" data-src="https://wx1.sbimg.cn/2020/07/18/ClGSk.png" alt="erzhihua"><br>　　可以类比将模拟信号转换成数字信号过程中的量化。<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_ = preprocessing.Binarizer(threshold=<span class="number">0</span>).transform(X)</span><br></pre></td></tr></table></figure></p><h4 id="哑编码-独热编码"><a href="#哑编码-独热编码" class="headerlink" title="哑编码/独热编码"></a>哑编码/独热编码</h4><p>　　哑编码/独热编码针对定性的特征进行处理。</p><h5 id="哑编码-dummy-encoding"><a href="#哑编码-dummy-encoding" class="headerlink" title="哑编码(dummy encoding)"></a>哑编码(dummy encoding)</h5><p>　　假设有N种定性值，则将这一个特征扩展为N种特征，当原始特征值为第i种定性值时，第i个扩展特征赋值为1，其他扩展特征赋值为0。哑编码的方式相比直接指定的方式，不用增加调参的工作，对于线性模型来说，使用哑编码后的特征可达到非线性的效果。<br>　　例如描述一个人的身材，我们可以用偏瘦、正常、偏胖，这些描述词经过哑编码就会得到：<br>　　　　偏廋 —&gt; [1, 0, 0]<br>　　　　正常 —&gt; [0, 1, 0]<br>　　　　偏胖 —&gt; [0, 0, 1]<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_ = pd.Categorical(df[<span class="string">'c'</span>]).codes</span><br></pre></td></tr></table></figure></p><h5 id="独热编码-one-hot-encoding"><a href="#独热编码-one-hot-encoding" class="headerlink" title="独热编码(one-hot encoding)"></a>独热编码(one-hot encoding)</h5><p>　　同上例，实际用2个状态位就足够反应上述3个类别的信息：<br>　　　　偏廋 —&gt; [1, 0]<br>　　　　正常 —&gt; [0, 1]<br>　　　　偏胖 —&gt; [0, 0]<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">encoder=OneHotEncoder(sparse=<span class="literal">False</span>) </span><br><span class="line"><span class="comment"># sparse是一个布尔值，指定结果是否稀疏。</span></span><br><span class="line"><span class="comment"># 若sparse=True，则每个样本的独热码为一个稀疏矩阵。</span></span><br></pre></td></tr></table></figure><br>  <br><br>　　关于哑编码/独热编码的区别和联系以及连续值的离散化提升模型的非线性能力的原因，可以参考<a href="https://www.cnblogs.com/lianyingteng/p/7792693.html" target="_blank" rel="noopener">这篇文章</a>。</p><h3 id="多特征"><a href="#多特征" class="headerlink" title="多特征"></a>多特征</h3><h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><p>　　数据预处理完成后，需要选择有意义的特征输入机器学习的算法和模型进行训练，一般从以下两个方面考虑：<br>　　· 特征是否发散（某特征不发散，说明对于区分样本作用并不大）<br>　　· 特征与目标的相关性  </p><p>　　特征选择主要包括：<br>　　· Filter Method （过滤式）<br>　　· Wrapper Method （包装式）<br>　　· Embedded Method （嵌入式）</p><h5 id="特征选择原理"><a href="#特征选择原理" class="headerlink" title="特征选择原理"></a>特征选择原理</h5><p>　　·去除无关特征可以降低学习任务的难度，也同样让模型变得简单，降低计算复杂度　　</p><h5 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h5><p>　　过滤式方法先对数据集进行特征选择，然后再训练模型，<strong>特征选择过程与后续模型训练无关</strong>。<br>　　通过统计学的方法对每个feature给出一个score，通过score对特征进行排序，然后选取score最高的子集.。这种方法仅仅对每个feature进行<strong>独立考虑</strong>，没有考虑到feture之间的依赖性或相关性。  </p><h6 id="方差选择法"><a href="#方差选择法" class="headerlink" title="方差选择法"></a>方差选择法</h6><p>　　计算各个特征的方差，根据阈值，<strong>选择方差大于阈值的特征</strong>。即若样本中该特征差异并不大，则认为该特征对于区分样本贡献不大，故可以将其去掉。<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"></span><br><span class="line">VarianceThreshold(threshold=<span class="number">0</span>).fit_transform(data)</span><br></pre></td></tr></table></figure></p><h6 id="相关系数法"><a href="#相关系数法" class="headerlink" title="相关系数法"></a>相关系数法</h6><p>　　计算各个特征对目标值的相关系数以及相关系数的P值。<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(map(<span class="keyword">lambda</span> x:pearsonr(x, Y), X.T)).T, </span><br><span class="line">            k=<span class="number">4</span>).fit_transform(data, target)</span><br><span class="line"><span class="comment"># 第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。（在此定义为计算相关系数）</span></span><br><span class="line"><span class="comment"># 参数k为选择的特征个数，选择k个最好的特征，返回选择特征后的数据</span></span><br></pre></td></tr></table></figure></p><h6 id="卡方检验"><a href="#卡方检验" class="headerlink" title="卡方检验"></a>卡方检验</h6><p>　　经典的卡方检验是<strong>检验定性自变量对定性因变量的相关性</strong>，是统计样本的实际观测值与理论推断值之间的偏离程度，实际观测值与理论推断值之间的偏离程度就决定卡方值的大小，如果卡方值越大，二者偏差程度越大；反之，二者偏差越小；若两个值完全相等时，卡方值就为0，表明理论值完全符合。<br>　　假设自变量有N种取值，因变量有M种取值，考虑自变量等于 i 且因变量等于 j 的样本频数的观察值与期望的差距。<br>　　<img src= "/img/loading.gif" data-src="https://wx1.sbimg.cn/2020/07/19/Cyng1.png" alt="x2"><br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2 </span><br><span class="line"><span class="comment"># 选择k个最佳特征</span></span><br><span class="line">SelectKBest(chi2, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure></p><h6 id="互信息法"><a href="#互信息法" class="headerlink" title="互信息法"></a>互信息法</h6><p>　　互信息(Mutual Information)是信息论里一种有用的信息度量，它可以看成是一个随机变量中包含的关于另一个随机变量的信息量，或者说是一个随机变量由于已知另一个随机变量而减少的不肯定性。<br>　　经典的互信息<strong>评价定性自变量对定性因变量的相关性</strong>。<br>　　设两个随机变量(X, Y)的联合分布为p(x, y)，边缘分布分别为p(x), p(y)，互信息I(X, Y)是联合分布p(x, y)与边缘分布p(x)p(y)的相对熵，即：<br><img src= "/img/loading.gif" data-src="https://wx1.sbimg.cn/2020/07/19/CV0Ek.png" alt="mutual info"><br> 　　关系图：<br><img src= "/img/loading.gif" data-src="https://wx2.sbimg.cn/2020/07/19/CVofa.png" alt="mutual"><br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> minepy <span class="keyword">import</span> MINE</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义mic方法将MINE设为函数式的，返回一个二元组，二元组的第2 项设置成固定的P值0.5</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mic</span><span class="params">(x, y)</span>:</span></span><br><span class="line">m = MINE()</span><br><span class="line">  m.compute_score(x, y)</span><br><span class="line">  <span class="keyword">return</span> (m.mic(), <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(map(<span class="keyword">lambda</span> x:mic(x, Y), X.T)).T,</span><br><span class="line">k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure></p><h5 id="Wrapper"><a href="#Wrapper" class="headerlink" title="Wrapper"></a>Wrapper</h5><p>　　包裹式特征选择直接把最终将要使用的模型的性能作为特征子集的评价标准，即包裹式特征选择的目的就是为给定的模型选择最有利于其性能的特征子集。从最终模型的性能来看，包裹式特征选择比过滤式特征选择更好，但需要多次训练模型，计算开销较大。<br><img src= "/img/loading.gif" data-src="https://wx2.sbimg.cn/2020/07/19/CVCpn.png" alt="filter mutual"></p><h6 id="递归特征消除法"><a href="#递归特征消除法" class="headerlink" title="递归特征消除法"></a>递归特征消除法</h6><p>　　递归特征消除法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处选择LR为基模型(estimator)</span></span><br><span class="line">RFE(estimator=LogisticRegression(), n_features_to_select=<span class="number">4</span>).fit_transform(data, target)</span><br></pre></td></tr></table></figure></p><h5 id="Embedded"><a href="#Embedded" class="headerlink" title="Embedded"></a>Embedded</h5><p>　　在前两种特征选择方法中，特征选择过程和模型训练过程是有明显分别的两个过程。嵌入式特征选择是<strong>将特征选择过程与学习器训练过程融为一体</strong>，两者在同一个优化过程中完成，即在学习器训练过程中自动地进行了特征选择。例如岭回归(Ridge)、LASSO回归。常利用正则化，如L1，L2范数，主要应用于如线性回归、逻辑回归以及支持向量机(SVM)等算法；使用决策树思想，包括决策树、随机森林、Gradient Boosting 等。<br>　　若使用L2范数正则化，则此时优化目标的公式即为岭回归(ridge regression)，若是L1范数正则化，则是LASSO回归(Least Absolute Shrinkage and Selection Operator)。L1范数和L2范数正则化都有助于降低过拟合风险，但前者还会带来一个额外的好处，它比后者更易于获得稀疏解，即它求得的w会有更少的非零分类。换言之，采用L1范数比L2范数更易于得到稀疏解。（参考<a href="https://zhuanlan.zhihu.com/p/120924870" target="_blank" rel="noopener">机器学习（六）：特征选择方法—Filter,Wrapper,Embedded</a>）</p><h6 id="基于惩罚项的特征选择法"><a href="#基于惩罚项的特征选择法" class="headerlink" title="基于惩罚项的特征选择法"></a>基于惩罚项的特征选择法</h6><p>　　使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维。<br>　　带L1惩罚项的LR：<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_selection import SelectFromModel</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line"> </span><br><span class="line">SelectFromModel(LogisticRegression(penalty&#x3D;&quot;l1&quot;, C&#x3D;0.1)).fit_transform(data, target)</span><br></pre></td></tr></table></figure></p><h6 id="基于树模型的特征选择法"><a href="#基于树模型的特征选择法" class="headerlink" title="基于树模型的特征选择法"></a>基于树模型的特征选择法</h6><p>　　GBDT作为基模型<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"></span><br><span class="line">SelectFromModel(GradientBoostingClassifier()).fit_transform(data, target)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言　　&quot;&gt;&lt;/a&gt;前言　　&lt;/h2&gt;&lt;p&gt;　　数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。&lt;/p&gt;
&lt;h2 id=&quot;特征工程&quot;&gt;&lt;a href=&quot;#特征
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>数据预处理——归一化与标准化</title>
    <link href="http://meurice.xyz/2020/ckcvmon6f0002p4lx9rud90xg/"/>
    <id>http://meurice.xyz/2020/ckcvmon6f0002p4lx9rud90xg/</id>
    <published>2020-07-17T09:33:10.000Z</published>
    <updated>2020-07-18T03:28:29.237Z</updated>
    
    <content type="html"><![CDATA[<p>归一化和标准化都属于四种Feature scaling（特征缩放）方法：<br>　　1.Rescaling(min-max normalization)<br>  <img src= "/img/loading.gif" data-src="https://wx1.sbimg.cn/2020/07/17/C8jCa.png" alt="Rescaling"><br>　　2.Mean normalization<br>  <img src= "/img/loading.gif" data-src="https://wx2.sbimg.cn/2020/07/17/C8h9n.png" alt="Mean normalization"><br>　　3.Standardization(Z-score normalization)<br>  <img src= "/img/loading.gif" data-src="https://wx1.sbimg.cn/2020/07/17/C8swh.png" alt="Standardization"><br>　　4.Scaling to unit length<br>  <img src= "/img/loading.gif" data-src="https://wx2.sbimg.cn/2020/07/17/C8JrM.png" alt="Scaling to unit length"></p><h2 id="归一化-Normalization"><a href="#归一化-Normalization" class="headerlink" title="归一化(Normalization)"></a>归一化(Normalization)</h2><h3 id="归一化目标"><a href="#归一化目标" class="headerlink" title="归一化目标"></a>归一化目标</h3><p>　　归一化将一列数据变化到某个固定区间（范围）中，这一区间通常是[0,1]，广义的讲，可以是各种区间，例如图像中可能会映射到[0,255]。<br>　　归一化使得各个特征维度对目标函数的影响权重是一致的，将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量，同时使得扁平分布的数据伸缩变换成类圆形。<br>　　概率模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率，如决策树、rf。而像Adaboost、、xgboost、SVM、LR、KNN、KMeans之类的最优化问题就需要归一化。</p><h3 id="归一化带来的好处"><a href="#归一化带来的好处" class="headerlink" title="归一化带来的好处"></a>归一化带来的好处</h3><p>　　Feature Sacling(Normalization)对基于Gradient descent算法友好，可让算法最终收敛并且提高训练速度和精度。<br>  <img src= "/img/loading.gif" data-src="https://wx2.sbimg.cn/2020/07/17/C8wYT.jpg" alt="scaling"></p><p>　　对于使用梯度下降算法来更新权重的训练过程，每一次更新的delta，除了与学习率有关，还与样本值本身也有关系。<br>  <img src= "/img/loading.gif" data-src="https://wx2.sbimg.cn/2020/07/17/C8vxJ.png" alt="gd"><br>　　Xj(i)就是当前更新批次对应的样本值，因此值越大的样本单次更新权重更快，这就有可能带来收敛速度不一样甚至不收敛等问题。</p><h3 id="归一化算法："><a href="#归一化算法：" class="headerlink" title="归一化算法："></a>归一化算法：</h3><p>　　1.线性转换：x’ = (x - min(x)) / (max(x) - min(x))<br>　　2.对数函数转换：x’ = lg(x) / lg(max)，其中max表示样本数据的最大值，所有样本数据均要大于等于1。<br>　　3.arctan反正切函数转换：x’ = arctan(x) * (2 / pi)，应注意的是，若希望映射的区间为[0,1]，则数据都应该大于等于0，小于0的数据将被映射到[-1,0]区间上。<br>　　4.L2范数归一化：对向量X的每个维度数据x1, x2, …, xn都除以||x||2得到一个新向量，即<br>  <img src= "/img/loading.gif" data-src="https://wx1.sbimg.cn/2020/07/17/C8imm.png" alt="l2"><br>　　经过L2范数归一化后，一组向量的欧式距离和它们的余弦相似度可以等价，严格数学证明可以参考<a href="https://www.cnblogs.com/Kalafinaian/p/11180519.html" target="_blank" rel="noopener">这篇文章</a>。</p><h2 id="标准化-Standardization"><a href="#标准化-Standardization" class="headerlink" title="标准化(Standardization)"></a>标准化(Standardization)</h2><h3 id="标准化目标"><a href="#标准化目标" class="headerlink" title="标准化目标"></a>标准化目标</h3><p>　　将数据变换为均值为0，标准差为1的分布（<strong>不一定是正态分布</strong>）。<br>　　<img src= "/img/loading.gif" data-src="https://wx2.sbimg.cn/2020/07/17/C8FgD.png" alt="st"></p><h2 id="联系与差异"><a href="#联系与差异" class="headerlink" title="联系与差异"></a>联系与差异</h2><h3 id="联系"><a href="#联系" class="headerlink" title="联系"></a>联系</h3><p>　　· Normalization和Standardization都是使数值都落入到统一的数值范围，消除了数据量纲的影响。  </p><h3 id="差异"><a href="#差异" class="headerlink" title="差异"></a>差异</h3><p>　　此处参考文章<a href="https://blog.csdn.net/weixin_36604953/article/details/102652160" target="_blank" rel="noopener">标准化和归一化，请勿混为一谈，透彻理解数据变换</a>。<br>　　· Normalization把数据限定在需要的范围，一般为[0,1]区间；Standardization将数据变换为μ=0，σ=1的分布，但没有严格规定区间。<br>　　· Normalization对数据的缩放比例仅仅和极值有关；但对于Standardization而言，若将除极大值和极小值外的数据更换，则均值和标准差也可能会因此改变，缩放比例也随之改变。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;归一化和标准化都属于四种Feature scaling（特征缩放）方法：&lt;br&gt;　　1.Rescaling(min-max normalization)&lt;br&gt;  &lt;img src= &quot;/img/loading.gif&quot; data-src=&quot;https://wx1.sbim
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Linux设置定时任务</title>
    <link href="http://meurice.xyz/2020/ckcvmon690000p4lx390m4i0g/"/>
    <id>http://meurice.xyz/2020/ckcvmon690000p4lx390m4i0g/</id>
    <published>2020-07-16T11:40:44.000Z</published>
    <updated>2020-07-17T14:22:00.702Z</updated>
    
    <content type="html"><![CDATA[<p>环境：CentOS 8</p><h3 id="执行内容"><a href="#执行内容" class="headerlink" title="执行内容"></a>执行内容</h3><p>　　新建文件_crond.sh，作为定时执行的内容。<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">cd &#x2F;www&#x2F;blog&#x2F;hexo</span><br><span class="line">git pull git@github.com:egname&#x2F;egrepo.git</span><br><span class="line"></span><br><span class="line">#echo pull successfully &gt; &#x2F;home&#x2F;gitpull.log</span><br></pre></td></tr></table></figure></p><h3 id="crontab服务"><a href="#crontab服务" class="headerlink" title="crontab服务"></a>crontab服务</h3><p>　　启动crontab服务，CentOS版本不同，具体命令可能有所差异。<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start crond</span><br></pre></td></tr></table></figure><br>　　启动服务</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop crond            # 关闭服务</span><br><span class="line">systemctl restart crond         # 重启服务     </span><br><span class="line">systemctl reload crond          # 重新载入配置</span><br><span class="line">systemctl status crond          # 状态</span><br></pre></td></tr></table></figure><h3 id="设置计时器"><a href="#设置计时器" class="headerlink" title="设置计时器"></a>设置计时器</h3><p>　　crontab 选项 参数<br>　　选项:<br>　　　　-e：编辑该用户的计时器设置；<br>　　　　-l：列出该用户的计时器设置；<br>　　　　-r：删除该用户的计时器设置；<br>　　　　-u：指定要设定计时器的用户名称。<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crontab -e</span><br></pre></td></tr></table></figure></p><p> 　　进入insert插入模式，以每五分钟执行一次为例。ESC后输入wq保存并退出。<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*&#x2F;5 * * * * &#x2F;root&#x2F;_crond.sh</span><br></pre></td></tr></table></figure><br>  <br></p><p>  关于Crontab更多具体用法，您可以参考<a href="https://www.cnblogs.com/muscles/p/9532451.html" target="_blank" rel="noopener">这篇文章</a>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;环境：CentOS 8&lt;/p&gt;
&lt;h3 id=&quot;执行内容&quot;&gt;&lt;a href=&quot;#执行内容&quot; class=&quot;headerlink&quot; title=&quot;执行内容&quot;&gt;&lt;/a&gt;执行内容&lt;/h3&gt;&lt;p&gt;　　新建文件_crond.sh，作为定时执行的内容。&lt;br&gt;  &lt;figure cla
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>[学习日志]2020 DIGIX全球校园AI算法精英大赛——赛道A</title>
    <link href="http://meurice.xyz/2020/ckcvmon6d0001p4lxh6tb4e9l/"/>
    <id>http://meurice.xyz/2020/ckcvmon6d0001p4lxh6tb4e9l/</id>
    <published>2020-07-16T04:23:28.000Z</published>
    <updated>2020-07-21T07:39:42.334Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2020-7-16"><a href="#2020-7-16" class="headerlink" title="2020.7.16"></a>2020.7.16</h2><p>　　7.20放赛题数据，先拿kaggle五年前的Click-Through Rate Prediction试水。</p><h3 id="分块读取全部数据"><a href="#分块读取全部数据" class="headerlink" title="分块读取全部数据"></a>分块读取全部数据</h3>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">loop = <span class="literal">True</span></span><br><span class="line">chunkSize = <span class="number">1000000</span></span><br><span class="line">chunks = []</span><br><span class="line">index = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> loop:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        print(index)</span><br><span class="line">        chunk = train_data.get_chunk(chunkSize)</span><br><span class="line">        chunks.append(chunk)</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line">  <span class="keyword">except</span> StopIteration:</span><br><span class="line">        loop = <span class="literal">False</span></span><br><span class="line">        print(<span class="string">"Iteration is stopped."</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(chunks):</span><br><span class="line">    train_data = pd.concat(chunks, ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="随机读取一定比例的数据"><a href="#随机读取一定比例的数据" class="headerlink" title="随机读取一定比例的数据"></a>随机读取一定比例的数据</h3>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> pd.read_csv(train_data, chunksize=chunksize):</span><br><span class="line">    chunks += <span class="number">1</span></span><br><span class="line">    train = pd.concat([train, chunk.sample(frac=<span class="number">.05</span>, replace=<span class="literal">False</span>, random_state=<span class="number">42</span>)], axis=<span class="number">0</span>) </span><br><span class="line">    print(<span class="string">'Processing Chunk '</span> + str(chunks))</span><br></pre></td></tr></table></figure><h3 id="条件筛选修改"><a href="#条件筛选修改" class="headerlink" title="条件筛选修改"></a>条件筛选修改</h3>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'column_d'</span>].loc[df[<span class="string">'column_c'</span>] == <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line"><span class="comment"># df['column_d'][df['column_c'] == 0] = 0</span></span><br></pre></td></tr></table></figure><h3 id="lightgbm-梯度提升决策树"><a href="#lightgbm-梯度提升决策树" class="headerlink" title="lightgbm 梯度提升决策树"></a>lightgbm 梯度提升决策树</h3>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kfold_lightgbm</span><span class="params">(train, test, features, target, seed=<span class="number">42</span>, is_shuffle=True)</span>:</span></span><br><span class="line">   train_pred = np.zeros((train.shape[<span class="number">0</span>],))</span><br><span class="line">   test_pred = np.zeros((test.shape[<span class="number">0</span>],))</span><br><span class="line">   n_splits = <span class="number">5</span>  </span><br><span class="line">   </span><br><span class="line">   fold = KFold(n_splits=n_splits, shuffle=is_shuffle, random_state=seed)</span><br><span class="line">   kf_way = fold.split(train[features])</span><br><span class="line"></span><br><span class="line">   params = &#123;</span><br><span class="line">       <span class="string">'learning_rate'</span>: <span class="number">0.003</span>,</span><br><span class="line">       <span class="string">'boosting_type'</span>: <span class="string">'gbdt'</span>,</span><br><span class="line">       <span class="string">'objective'</span>: <span class="string">'regression'</span>,</span><br><span class="line">       <span class="string">'num_leaves'</span>: <span class="number">36</span>,</span><br><span class="line">       <span class="string">'metric'</span>: <span class="string">'mse'</span>,</span><br><span class="line">       <span class="string">'feature_fraction'</span>: <span class="number">0.6</span>,</span><br><span class="line">       <span class="string">'bagging_fraction'</span>: <span class="number">0.7</span>,</span><br><span class="line">       <span class="string">'bagging_freq'</span>: <span class="number">6</span>,</span><br><span class="line">       <span class="string">'seed'</span>: <span class="number">42</span>,</span><br><span class="line">       <span class="string">'bagging_seed'</span>: <span class="number">1</span>,</span><br><span class="line">       <span class="string">'feature_fraction_seed'</span>: <span class="number">7</span>,</span><br><span class="line">       <span class="string">'min_data_in_leaf'</span>: <span class="number">7</span>,</span><br><span class="line">       <span class="string">'nthread'</span>: <span class="number">8</span>,</span><br><span class="line">       <span class="string">'verbose'</span>: <span class="number">1</span>,</span><br><span class="line">   &#125;</span><br><span class="line">   fold_importance_df = pd.DataFrame()</span><br><span class="line">   <span class="keyword">for</span> n_fold, (train_idx, valid_idx) <span class="keyword">in</span> enumerate(kf_way, start=<span class="number">1</span>):</span><br><span class="line">       train_x, train_y = train[features].iloc[train_idx], train[target].iloc[train_idx]</span><br><span class="line">       valid_x, valid_y = train[features].iloc[valid_idx], train[target].iloc[valid_idx]</span><br><span class="line"></span><br><span class="line">       n_train = lgb.Dataset(train_x, label=train_y)</span><br><span class="line">       n_valid = lgb.Dataset(valid_x, label=valid_y)</span><br><span class="line"></span><br><span class="line">       clf = lgb.train(</span><br><span class="line">           params= params,</span><br><span class="line">           train_set= n_train,</span><br><span class="line">           num_boost_round= <span class="number">10000</span>,</span><br><span class="line">           valid_sets= [n_valid],</span><br><span class="line">           early_stopping_rounds= <span class="number">150</span>,</span><br><span class="line">           verbose_eval= <span class="number">100</span></span><br><span class="line">       )</span><br><span class="line">       train_pred[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration)</span><br><span class="line">       test_pred += clf.predict(test[features], num_iteration=clf.best_iteration) / fold.n_splits</span><br><span class="line"></span><br><span class="line">       fold_importance_df[<span class="string">"Feature"</span>] = features</span><br><span class="line">       fold_importance_df[<span class="string">"importance"</span>] = clf.feature_importance(importance_type=<span class="string">'gain'</span>)</span><br><span class="line">       fold_importance_df[<span class="string">"fold"</span>] = n_splits</span><br><span class="line"></span><br><span class="line">   test[TARGET] = test_pred</span><br><span class="line">   <span class="keyword">return</span> test[[<span class="string">'id'</span>, TARGET]], fold_importance_df</span><br></pre></td></tr></table></figure><h3 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h3>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> cat_features:</span><br><span class="line">    ce_oe = ce.OrdinalEncoder(cols=cat_features, handle_unknown=<span class="string">'impute'</span>)</span><br><span class="line">    ce_oe.fit(train)</span><br><span class="line">    train = ce_oe.transform(train)</span><br><span class="line">    test = ce_oe.transform(test)</span><br></pre></td></tr></table></figure><h2 id="2020-7-20"><a href="#2020-7-20" class="headerlink" title="2020.7.20"></a>2020.7.20</h2><p>　　下午官网放了赛题数据，随机抽了5%的数据放进GBDT跑了一下，目测效果并不是很好，CTR标签分布很不均匀，训练集标签为1的样本大概只占到了3%。</p><h3 id="结果出现负值"><a href="#结果出现负值" class="headerlink" title="结果出现负值"></a>结果出现负值</h3><p>　　GBDT是加法模型，下一轮都是上一轮预测值和实际值的残差作为label继续拟合，将结果相加，最后可能会出现负值，特别是例如CTR场景下大部分标签都为0的场景下更容易出现这种情况。</p><h2 id="2020-7-21"><a href="#2020-7-21" class="headerlink" title="2020.7.21"></a>2020.7.21</h2><p>　　丢了几个缺失比较大的特征，对数据做了简单随机采样之后跑lgb5折交了一发，线上分数能到0.7，比预想中的要好，还有一定的提升空间，下一步打算从模型角度切入。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;2020-7-16&quot;&gt;&lt;a href=&quot;#2020-7-16&quot; class=&quot;headerlink&quot; title=&quot;2020.7.16&quot;&gt;&lt;/a&gt;2020.7.16&lt;/h2&gt;&lt;p&gt;　　7.20放赛题数据，先拿kaggle五年前的Click-Through Rate
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Hexo+Nginx搭建静态页面博客</title>
    <link href="http://meurice.xyz/2020/ckcvmonbz0005p4lx8bmugxc7/"/>
    <id>http://meurice.xyz/2020/ckcvmonbz0005p4lx8bmugxc7/</id>
    <published>2020-07-15T07:54:00.000Z</published>
    <updated>2020-07-16T10:32:32.590Z</updated>
    
    <content type="html"><![CDATA[<p>Hexo 是一个快速、简洁且高效的博客框架，且支持 Markdown 语法。</p><p>• 本地环境配置：Node.js+Git+Hexo <br><br>• ECS环境配置：(CentOs 8) Node.js+Git+Pm2+Nginx <br><br>• 安全组配置：阿里云ECS <br><br>• 域名：腾讯云域名解析 <br><br>• Webhook：Github</p><h3 id="本地环境配置"><a href="#本地环境配置" class="headerlink" title="本地环境配置 "></a>本地环境配置 <br></h3><h4 id="Node-js"><a href="#Node-js" class="headerlink" title="Node.js "></a>Node.js <br></h4><p>　Node.js官网<a href="https://nodejs.org/en/" target="_blank" rel="noopener">Node.js</a>，安装目录尽量不要包括空格，命令行下<code>node -v</code>验证是否安装成功。<br><br>　或通过<a href="https://npm.taobao.org/mirrors/node" target="_blank" rel="noopener">淘宝npm镜像</a>安装。</p><h4 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git<br></h4><h5 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h5><p>　Git官网 <a href="https://git-scm.com/" target="_blank" rel="noopener">Git</a>，命令行<code>git --version</code>验证。</p><h5 id="SSH配置"><a href="#SSH配置" class="headerlink" title="SSH配置"></a>SSH配置</h5><p>　　配置Github用户名 <br><br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;example&quot;</span><br><span class="line">git config --global user.email &quot;example@email.com&quot;</span><br></pre></td></tr></table></figure><br>　　生成秘钥<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C &quot;example@email.com&quot;</span><br></pre></td></tr></table></figure></p><p>　　~/.ssh文件夹下生成id_rsa.pub公有密钥，依次进入Github——Settings——SSH and GPG keys，添加SSH key，将d_rsa.pub中的内容放入Key中。具体可以参考<a href="https://blog.csdn.net/playboyanta123/article/details/49611873?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase" target="_blank" rel="noopener">这篇文章</a>，Linux系统可以参考<a href="https://blog.csdn.net/qq_36663951/article/details/78749217?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-1" target="_blank" rel="noopener">这篇文章</a>。</p><h4 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo<br></h4><p>　　npm全局安装<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install -g hexo-cli</span><br></pre></td></tr></table></figure></p><p>　　验证<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo -version</span><br></pre></td></tr></table></figure></p><p>　　新建文件夹用来存放Hexo代码，在该文件夹下执行命令行。<br>　　初始化Hexo，生成相关文件。<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo -init</span><br></pre></td></tr></table></figure></p><p>　　安装相关依赖<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure></p><p>　　预览效果<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure><br>　　浏览器进入<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a></p><h4 id="发布到Github"><a href="#发布到Github" class="headerlink" title="发布到Github"></a>发布到Github<br></h4><p>　　安装git部署工具<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><br>　　修改_config.yml，repo字段修改为github仓库的SSH链接。<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">type: git</span><br><span class="line">repo:git@github.com:egname&#x2F;egrepo.git</span><br><span class="line">branch: master</span><br></pre></td></tr></table></figure><br>　　代码上传至Github<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></p><h3 id="ECS环境配置"><a href="#ECS环境配置" class="headerlink" title="ECS环境配置 "></a>ECS环境配置 <br></h3><p>　　服务器为阿里云ECS云服务器，CentOS 8。</p><h4 id="Node-js-1"><a href="#Node-js-1" class="headerlink" title="Node.js"></a>Node.js<br></h4><p>　　采用yum方式安装<br>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -sL https:&#x2F;&#x2F;rpm.nodesource.com&#x2F;setup_10.x | bash -</span><br><span class="line">yum install -y nodejs</span><br><span class="line"></span><br><span class="line">node -v # 验证</span><br></pre></td></tr></table></figure></p><h4 id="Git-1"><a href="#Git-1" class="headerlink" title="Git "></a>Git <br></h4>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install git</span><br><span class="line"></span><br><span class="line">git --version # 验证</span><br></pre></td></tr></table></figure><h5 id="SSH配置-1"><a href="#SSH配置-1" class="headerlink" title="SSH配置"></a>SSH配置<br></h5>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;example&quot;</span><br><span class="line">git config --global user.email &quot;example@email.com&quot;</span><br><span class="line"></span><br><span class="line">ssh-keygen -t rsa -b 4096 -C &quot;example@email.com&quot;</span><br></pre></td></tr></table></figure><p>　　复制公有密钥，在Github上添加新的SSH key，具体可参考上文本地配置。<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~&#x2F;.ssh</span><br><span class="line">cat id_rsa.pub</span><br></pre></td></tr></table></figure><br>　　从Github仓库中克隆代码。<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;</span><br><span class="line">mkdir www</span><br><span class="line"> </span><br><span class="line">cd www</span><br><span class="line">mkdir blog</span><br><span class="line"></span><br><span class="line">cd blog</span><br><span class="line">git clone git@github.com:egname&#x2F;egrepo.git</span><br></pre></td></tr></table></figure></p><h4 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx "></a>Nginx <br></h4><p>　　安装EPEL存储库<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install epel-release</span><br></pre></td></tr></table></figure></p><p>　　安装Nginx<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install nginx</span><br></pre></td></tr></table></figure><br>　　启动Nginx，设置自启动<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start nginx</span><br><span class="line">sudo systemctl enable nginx</span><br></pre></td></tr></table></figure></p><h5 id="Nginx配置"><a href="#Nginx配置" class="headerlink" title="Nginx配置"></a>Nginx配置</h5><p>　　进入etc/nginx文件夹下的nginx.conf<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi &#x2F;etc&#x2F;nginx&#x2F;nginx.conf</span><br></pre></td></tr></table></figure><br>　　修改配置文件<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">  listen 80;</span><br><span class="line">  server_name www.example.com;</span><br><span class="line">  root &#x2F;www&#x2F;blog&#x2F;example;</span><br><span class="line">  include &#x2F;etc&#x2F;nginx&#x2F;default.d&#x2F;*.conf;</span><br><span class="line">  </span><br><span class="line">  location &#x2F; &#123;</span><br><span class="line">    root &#x2F;www&#x2F;blog&#x2F;example;</span><br><span class="line">    index index.jsp index.html index.htm;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>　　重启Nginx<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart nginx</span><br></pre></td></tr></table></figure></p><h3 id="安全组配置"><a href="#安全组配置" class="headerlink" title="安全组配置"></a>安全组配置</h3><p>　　以阿里云ECS为例。<br>　　进入控制台——网络与安全——安全组，添加入方向规则。<br>　　添加端口范围分别为80/80（HTTP），443/443（HTTPS），7777/7777（Webhook），授权对象均为0.0.0.0/0。</p><h3 id="域名解析"><a href="#域名解析" class="headerlink" title="域名解析"></a>域名解析</h3><p>　　以腾讯云为例。<br>　　DNS 解析 DNSPod——域名解析列表——选择域名——添加记录——快速添加网站解析——指定服务器主机IP（公网）。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Hexo 是一个快速、简洁且高效的博客框架，且支持 Markdown 语法。&lt;/p&gt;
&lt;p&gt;• 本地环境配置：Node.js+Git+Hexo &lt;br&gt;&lt;br&gt;• ECS环境配置：(CentOs 8) Node.js+Git+Pm2+Nginx &lt;br&gt;&lt;br&gt;• 安全组配
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://meurice.xyz/2020/ckcvmon6g0003p4lx9jrr7tdx/"/>
    <id>http://meurice.xyz/2020/ckcvmon6g0003p4lx9jrr7tdx/</id>
    <published>2020-07-15T04:29:57.340Z</published>
    <updated>2020-07-15T04:29:57.340Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
