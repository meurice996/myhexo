title: '[赛后总结]山东省第二届数据应用创新创业大赛-主赛场——疫情密切接触人员追踪'
author: meurice
date: 2021-04-03 23:13:06
tags:
---
## 写在前面
　　回想过去一年所参加过的各种类型的竞赛，表格、CV、NLP...，而性能优化的题还是第一次接触，对这场比赛也投入了不少时间和精力，从三月初的第一次提交到复赛结束，这场比赛，**有收获也有遗憾**。  
## 赛题介绍
### 赛题任务
　　通过筛选个人基本信息、个人防疫信息、亮码位置、亮码时间等数据，判定直接密接人员，间接密接人员，判定疫情传播风险等级，辅助决策疫情防控力度。  
### 评分标准
　　准确率分数使用**macro F1**计算。

　　直接密接人员：与确诊患者亮码时间差的绝对值在5分钟内，距离在10米以内。  
　　间接密接人员：与直接密接人员的亮码时间差的绝对值在5分钟内，距离在10米以内。  
　　如果既是直接密接人员又是间接密接人员，统一归类为直接密接人员。
 
　　距离计算参考函数如下：
```Python
from math import radians, cos, sin, asin, sqrt
def geodistance(lng1, lat1, lng2, lat2):
	lng1, lat1, lng2, lat2 = map(radians, [float(lng1), float(lat1), float(lng2), float(lat2)])
    dlon = lng2-lng1
    dlat = lat2-lat1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    distance = 2 * asin(sqrt(a)) * 6371.393 * 1000
    distance = round(distance, 5)
    return distance
```
### 数据集描述
　　**个人轨迹数据（df_travel.csv）**：  
　　id：String，人员唯一ID  
　　usetime：Date，亮码时间  
　　lng：Float，亮码位置经度（小数点5位，GCJ02坐标系）  
　　lat：Float，亮码位置纬度（小数点5位，GCJ02坐标系）  
  
　　**确诊患者亮码记录（confirm.csv）**：   
　　亮码时间：Date，亮码时间；  
　　lng：Float，亮码位置经度（小数点5位，GCJ02坐标系）  
　　lat：Float，亮码位置纬度（小数点5位，GCJ02坐标系）  
　　备注：String，确诊患者的具体行为  
　　*只有一名确诊患者*
## 解决思路
　　整体上来看，方案比较常规，决赛还未开始，对于这题有没有一些特殊的方法，还需要等待答辩结束。  位于Rank5的江离重楼大佬在复赛结束后就分享了自己的代码和思路  
　　为每条轨迹记录添加唯一索引，先根据确诊人员信息和条件判断出直接密接的记录，根据这些记录筛选每个id在接触时间以后的所有记录，最后再根据这些记录和条件判断间接密接人员，**先初筛，后细筛**。
### 直接密接人员
　　轨迹数据的规模为200万+条，确诊人员记录约为50条，规模并不大，所以直接考虑计算所有点对之间的Euclidean Distance / CityBlock Distance，筛选出亮码时间差在300秒以内以及经纬度距离在0.00025内的点对，再根据经纬度计算精确距离差，筛选出直接密接人员。  
　　在复赛阶段对这个方案又做了一些小优化，在线下环境成绩有所提升。由于确诊人员记录数量极少，所以根据这些点的经纬度及时间可以先大幅缩小搜索范围，即先使用集合运算挑选出处在可能范围内的人员轨迹记录，再做如上操作，代码如下。  
```Python
def gen_idx_direct(candidate, target):
    set_target_time = set([j for i in target.time for j in range(i - 300,i + 301)]) 
    set_target_lng = set(np.around([j for i in target.lng for j in np.arange(i - 0.00025,i + 0.00025,0.00001)], 5))
    set_target_lat = set(np.around([j for i in target.lat for j in np.arange(i - 0.00025,i + 0.00025,0.00001)], 5))

    candidate_ = candidate[(
                    candidate.time.isin(list(set_target_time))) & (
                    np.round(candidate.lng, 5).isin(list(set_target_lng))) & (
                    np.round(candidate.lat, 5).isin(list(set_target_lat)))].reset_index(drop=True)

    time_diff = np.where(
                    abs(cdist(candidate_[['time','temp']],
                        target[['time','temp']], metric='cityblock')) <= 300, 1, 0)
    distance = np.where(
                    abs(cdist(candidate_[['lng', 'lat']],
                        target[['lng', 'lat']])) <= 0.00025, 1, 0)
    result_mat = time_diff * distance

    c_idx = np.where(result_mat == 1)[0]
    t_idx = np.where(result_mat == 1)[1]

    distance = geodistance(candidate_.iloc[c_idx, 3],
                           candidate_.iloc[c_idx, 2],
                           target.iloc[t_idx, 2],
                           target.iloc[t_idx, 1])

    c_result = c_idx[np.where(distance <= 10)[0]]
    # t_result = t_idx[np.where(distance <= 10)[0]]
   
    return candidate_.loc[list(set(c_result)), 'idx'].tolist()
```
　　**对距离计算函数进行了修改**，使用numpy，改为矩阵并行计算。
```Python
import numexpr as ne
def geodistance(lng1, lat1, lng2, lat2):
    lng1 = np.radians(np.array(lng1))
    lat1 = np.radians(np.array(lat1))
    lng2 = np.radians(np.array(lng2))
    lat2 = np.radians(np.array(lat2))
    return np.round(ne.evaluate("2 * arcsin(sqrt(sin((lat2 - lat1) / 2) ** 2 + cos(lat1) * cos(lat2) * sin((lng2 - lng1) / 2) ** 2)) * 6371.393 * 1000"), 5)
```
### 间接密接人员
　　关于间接密接人员的搜索，尝试了两种方案，一种是使用KD树，另一种是将经纬度以一定的尺度网格化（0.0001），对于直接密接人员的记录，搜索其附近的九个格子。  
　　我所使用的是KD树的方案，然而比赛结束后看到Rank5 江离.重楼大佬在群里的分享，也是使用的网格化搜索的方案，不过语言方面使用的是C++，这才意识到针对计算密集型程序Python和C++巨大的效率差距，初赛阶段看到以Python作为入口语言，就默认用Python实现了，复赛阶段也一直没向这个方向进行优化，最后只排到了Rank16，这也是做这次比赛的遗憾之处吧~
#### K-D Tree
　　kd（k-dimensional）树的概念自1975年提出，试图解决的是在k维空间为数据集建立索引的问题，即已知样本空间如何快速查询得到其近邻？它的思想如同分治法，即：利用已有数据对k维空间进行切分。  
　　Scipy中提供了KDTree的接口，scipy.spatial.cKDTree，其底层使用C语言实现，效率更高。
```Python
def gen_idx_indirect_kd(candidate, target):
    candidate.reset_index(inplace=True, drop=True)
    target.reset_index(inplace=True, drop=True)
    
    kd_time_diff = cKDTree(candidate[['time']])
    time_diff_idx = kd_time_diff.query_ball_point(target[['time']].values.tolist(), r = 300, p = 1)

    kd_distance = cKDTree(candidate[['lng','lat']])
    distance_idx = kd_distance.query_ball_point(target[['lng','lat']].values.tolist(), r = 0.00025, p = 2)

    intersection = []
    for i in range(len(distance_idx)):
        intersection.append(list(set(distance_idx[i]).intersection(set(time_diff_idx[i]))))

    c_idx = []
    t_idx = []
    for i in range(len(intersection)):
        c_idx.extend(intersection[i])
        t_idx.extend([i] * len(intersection[i]))

    distance = geodistance(candidate.iloc[c_idx, 3],
                           candidate.iloc[c_idx, 2],
                           target.iloc[t_idx, 3],
                           target.iloc[t_idx, 2])

    c_result = [c_idx[i] for i in (np.where((distance <= 10))[0]).tolist()]

    return candidate.iloc[list(set(c_result)), 0].tolist()
```
#### 网格化搜索
　　网格化搜索实现起来相对比较简单，其思想类似于GeoHash，即将二位的经纬度坐标点映射到一维，但GeoHash在这里并不适合，一方面是效率过低，另一方面，和直接将经纬度点映射到0,1,...,n的效果相同。  
  ![GeoHash](https://hexo-img-meurice.oss-cn-beijing.aliyuncs.com/ShanDongBD_covid/2095550-d86dc182d102451b.png)
　　具体实现待补充...
## 关于效率
　　复赛结束时，线上成绩约为30s，并不算优秀，但站在纯Python语言的角度来看应该不算慢。
　　除计算外，I/O方面的优化也是本题的上分点之一。  
　　关于效率的计算，比较奇怪的是，线上评测成绩的抖动幅度似乎不小，我个人第一次和第二次提交的代码几乎相同，但线上成绩提升了近30%，除此之外，主办方所的线上环境只开放了CPU的一个核心，但经过实验，多进程对该题是work的，能带来大概25%的提升。但如果时间效率足够高的话，多进程显然就不太合适了，进程创建和切换所带来的开销已经不能忽略不计了。  
　　待补充...
## 关于准确率
　　初赛使用该方案的macro F1为1.0，但是对于复赛阶段的数据为0.999179，针对复赛的数据如何达到1.0还需要等决赛答辩后学习思路。  
　　待补充...
## 个人实现完整代码
　　**由纯Python实现**，和C/C++等语言的实现相比，时间效率并不算高，仅供参考。
```Python
import pandas as pd
import numpy as np
from datetime import datetime
from scipy.spatial.distance import cdist
from scipy.spatial import cKDTree
import numexpr as ne
import os
import multiprocessing
import sys

def geodistance(lng1, lat1, lng2, lat2):
    lng1 = np.radians(np.array(lng1))
    lat1 = np.radians(np.array(lat1))
    lng2 = np.radians(np.array(lng2))
    lat2 = np.radians(np.array(lat2))
    return np.round(ne.evaluate("2 * arcsin(sqrt(sin((lat2 - lat1) / 2) ** 2 + cos(lat1) * cos(lat2) * sin((lng2 - lng1) / 2) ** 2)) * 6371.393 * 1000"), 5)

def gen_idx_direct(candidate, target):
    set_target_time = set([j for i in target.time for j in range(i - 300,i + 301)]) 
    set_target_lng = set(np.around([j for i in target.lng for j in np.arange(i - 0.00025,i + 0.00025,0.00001)], 5))
    set_target_lat = set(np.around([j for i in target.lat for j in np.arange(i - 0.00025,i + 0.00025,0.00001)], 5))

    candidate_ = candidate[(
                    candidate.time.isin(list(set_target_time))) & (
                    np.round(candidate.lng, 5).isin(list(set_target_lng))) & (
                    np.round(candidate.lat, 5).isin(list(set_target_lat)))].reset_index(drop=True)

    time_diff = np.where(
                    abs(cdist(candidate_[['time','temp']],
                        target[['time','temp']], metric='cityblock')) <= 300, 1, 0)
    distance = np.where(
                    abs(cdist(candidate_[['lng', 'lat']],
                        target[['lng', 'lat']])) <= 0.00025, 1, 0)
    result_mat = time_diff * distance

    c_idx = np.where(result_mat == 1)[0]
    t_idx = np.where(result_mat == 1)[1]

    distance = geodistance(candidate_.iloc[c_idx, 3],
                           candidate_.iloc[c_idx, 2],
                           target.iloc[t_idx, 2],
                           target.iloc[t_idx, 1])

    c_result = c_idx[np.where(distance <= 10)[0]]
    t_result = t_idx[np.where(distance <= 10)[0]]

    return candidate_.iloc[list(set(c_result)), 4].tolist(), pd.concat([candidate_.iloc[c_result,[0,6]].reset_index(drop=True), (target.iloc[t_result,6]).reset_index(drop=True)],axis=1,ignore_index=True)

def gen_idx_indirect_kd(candidate, target):
    candidate.reset_index(inplace=True, drop=True)
    target.reset_index(inplace=True, drop=True)
    
    kd_time_diff = cKDTree(candidate[['time']])
    time_diff_idx = kd_time_diff.query_ball_point(target[['time']].values.tolist(), r = 300, p = 1)

    kd_distance = cKDTree(candidate[['lng','lat']])
    distance_idx = kd_distance.query_ball_point(target[['lng','lat']].values.tolist(), r = 0.00025, p = 1)

    intersection = []
    for i in range(len(distance_idx)):
        intersection.append(list(set(distance_idx[i]).intersection(set(time_diff_idx[i]))))

    c_idx = []
    t_idx = []
    for i in range(len(intersection)):
        c_idx.extend(intersection[i])
        t_idx.extend([i] * len(intersection[i]))

    distance = geodistance(candidate.iloc[c_idx, 3],
                           candidate.iloc[c_idx, 2],
                           target.iloc[t_idx, 3],
                           target.iloc[t_idx, 2])

    c_result = [c_idx[i] for i in (np.where((distance <= 10))[0]).tolist()]
    
    return candidate.iloc[list(set(c_result)), 0].tolist()

def main(dirname, savePath):
    confirmPath = os.path.join(dirname, "confirm.csv")
    travelPath = os.path.join(dirname, "df_travel.csv")
    
    confirmed = pd.read_csv(confirmPath)
    df_travel = pd.read_csv(travelPath)

    confirmed['亮码时间'] = pd.to_datetime(confirmed['亮码时间'],format='%Y-%m-%d %H:%M:%S')
    df_travel['usetime'] = pd.to_datetime(df_travel['usetime'],format='%Y-%m-%d %H:%M:%S')
    
    df_travel_length = len(df_travel)

    confirmed['idx'] = range(len(confirmed))
    df_travel['idx'] = range(df_travel_length)

    confirmed['temp'] = 0
    df_travel['temp'] = 0

    confirmed['time'] = (pd.to_timedelta(confirmed['亮码时间'] - datetime(2020, 10, 30)).dt.total_seconds()).astype(int)
    df_travel['time'] = (pd.to_timedelta(df_travel['usetime'] - datetime(2020, 10, 30)).dt.total_seconds()).astype(int)
    
    direct_idx, df_direct_min_time_ = gen_idx_direct(df_travel, confirmed)
    df_direct_min_time_.columns = ['id','ctime_direct', 'ctime_confirm']
    
    df_direct = df_travel[df_travel['idx'].isin(direct_idx)]

    df_travel = pd.merge(df_travel, df_direct_min_time_.groupby('id').agg({'ctime_direct':min}), on='id', how='left')
    df_travel.ctime_direct.fillna(-1,inplace=True)

    df_travel['direct'] = 0
    df_travel.loc[(df_travel['time'] >= df_travel['ctime_direct']) & (df_travel['ctime_direct'] >= 0),'direct'] = 1

    df_direct = df_travel[df_travel['direct'] == 1]

    #df_indirect_min_time = gen_idx_indirect_kd(df_travel[df_travel['direct'] == 0], df_direct)
    #indirect_id = df_indirect_min_time.id_i.tolist()

    p_i = multiprocessing.Pool(3)
    indirect_id_0 = p_i.apply_async(gen_idx_indirect_kd, args=(df_travel.iloc[np.arange(0, df_travel_length, 3)], df_direct))
    indirect_id_1 = p_i.apply_async(gen_idx_indirect_kd, args=(df_travel.iloc[np.arange(1, df_travel_length, 3)], df_direct))
    indirect_id_2 = p_i.apply_async(gen_idx_indirect_kd, args=(df_travel.iloc[np.arange(2, df_travel_length, 3)], df_direct))
    p_i.close()
    p_i.join()

    submission = pd.DataFrame({'id':list(set(df_travel['id'].tolist())),'label':0})
    submission.loc[submission['id'].isin(list(set([i for l in [indirect_id_0.get(),indirect_id_1.get(),indirect_id_2.get()] for i in l]))),'label'] = 2
    submission.loc[submission['id'].isin(df_direct['id'].tolist()),'label'] = 1
    submission.to_csv(savePath,index=False)

if __name__ == "__main__":
    dirname = sys.argv[1]  # 所需预测的文件夹
    savePath = sys.argv[2]  # 预测结果保存文件
    main(dirname, savePath)
```
## 写在最后